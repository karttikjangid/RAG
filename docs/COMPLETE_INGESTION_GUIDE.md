# RAG System - Complete Data Ingestion Guide

## ğŸ“š Overview

The RAG system now supports **three different data sources**, each with its own specialized ingestion module. All modules output clean text ready for the RAG pipeline.

---

## ğŸ”§ Available Ingestion Modules

### 1ï¸âƒ£ Text File Ingestion
**File**: `data_ingestion.py`  
**Function**: `reading_data(file_path)`  
**Use Case**: Plain text files, markdown, code files

```python
from data_ingestion import reading_data

text = reading_data("notes.txt")
```

**Features**:
- âœ… UTF-8 encoding support
- âœ… Simple and fast
- âœ… Any text-based file format

---

### 2ï¸âƒ£ YouTube Video Transcripts
**File**: `youtube_ingestion.py`  
**Function**: `get_youtube_transcript(url)`  
**Use Case**: Educational videos, tutorials, lectures

```python
from youtube_ingestion import get_youtube_transcript

url = "https://www.youtube.com/watch?v=jNQXAC9IVRw"
text = get_youtube_transcript(url)
```

**Features**:
- âœ… Automatic subtitle extraction
- âœ… Timestamp removal
- âœ… Support for auto-generated & manual captions
- âœ… Multiple language support
- ğŸ“¦ Library: `youtube-transcript-api`

---

### 3ï¸âƒ£ PDF Documents
**File**: `pdf_ingestion.py`  
**Function**: `get_pdf_text(file_path)`  
**Use Case**: Research papers, books, reports, resumes

```python
from pdf_ingestion import get_pdf_text

text = get_pdf_text("research_paper.pdf")
```

**Features**:
- âœ… Multi-page extraction
- âœ… Automatic text cleaning
- âœ… Progress indicators
- âœ… Comprehensive error handling
- ğŸ“¦ Library: `pypdf`

---

## ğŸ¯ Quick Comparison

| Feature | Text Files | YouTube | PDF |
|---------|-----------|---------|-----|
| **Module** | `data_ingestion.py` | `youtube_ingestion.py` | `pdf_ingestion.py` |
| **Input** | File path | YouTube URL | File path |
| **Library** | Built-in | `youtube-transcript-api` | `pypdf` |
| **Speed** | âš¡ Instant | ğŸ”„ 2-5 sec | âš¡ < 1 sec |
| **Pages** | N/A | Single video | Multiple pages |
| **Error Handling** | Basic | Advanced | Advanced |
| **Output Format** | Raw text | Clean transcript | Combined pages |

---

## ğŸš€ Complete RAG Pipeline Integration

### Multi-Source RAG Example

```python
from data_ingestion import reading_data
from youtube_ingestion import get_youtube_transcript
from pdf_ingestion import get_pdf_text
from chunking import get_chunks
from embedding import vector_embedding
from retrieval import search_best_chunks
from generation import generate_answer

# 1. Gather data from multiple sources
text_data = reading_data("notes.txt")
youtube_data = get_youtube_transcript("https://youtube.com/watch?v=...")
pdf_data = get_pdf_text("research.pdf")

# 2. Combine all sources
all_text = text_data + " " + youtube_data + " " + pdf_data

# 3. Process through RAG pipeline
chunks = get_chunks(all_text, chunk_size=200, overlap=50)
vectors, model = vector_embedding(chunks)

# 4. Query the system
query = "What is RAG?"
results = search_best_chunks(query, model, vectors, chunks, k=3)

# 5. Generate answer
answer = generate_answer(query, results[0]['text'])
print(answer)
```

---

## ğŸ“¦ Installation Requirements

```bash
# Activate virtual environment
source venv/bin/activate

# Install all required libraries
pip install sentence-transformers    # For embeddings
pip install scikit-learn             # ML utilities
pip install requests                 # HTTP requests
pip install youtube-transcript-api   # YouTube transcripts
pip install pypdf                    # PDF extraction
pip install reportlab                # PDF creation (testing)
```

---

## âœ… Testing Each Module

### Test Text Ingestion
```bash
python data_ingestion.py
# Expected: Character count of data.txt
```

### Test YouTube Ingestion
```bash
python youtube_ingestion.py
# Expected: Transcript from first YouTube video
```

### Test PDF Ingestion
```bash
python pdf_ingestion.py
# Expected: Text from sample.pdf (3 pages)
```

### Test Full Integration
```bash
python pdf_rag_example.py
# Expected: Complete RAG workflow with Q&A
```

---

## ğŸ“ Module Architecture

```
RAG_SYSTEM/
â”‚
â”œâ”€â”€ ğŸ“¥ DATA INGESTION LAYER
â”‚   â”œâ”€â”€ data_ingestion.py         (Text files)
â”‚   â”œâ”€â”€ youtube_ingestion.py      (YouTube videos)
â”‚   â””â”€â”€ pdf_ingestion.py          (PDF documents)
â”‚
â”œâ”€â”€ âš™ï¸ PROCESSING LAYER
â”‚   â”œâ”€â”€ chunking.py               (Text splitting)
â”‚   â””â”€â”€ embedding.py              (Vector creation)
â”‚
â”œâ”€â”€ ğŸ” RETRIEVAL LAYER
â”‚   â””â”€â”€ retrieval.py              (Semantic search)
â”‚
â”œâ”€â”€ ğŸ¤– GENERATION LAYER
â”‚   â””â”€â”€ generation.py             (LLM answers)
â”‚
â””â”€â”€ ğŸ¯ ORCHESTRATION
    â””â”€â”€ main.py                   (Complete pipeline)
```

---

## ğŸ“Š Real-World Use Cases

### Use Case 1: Academic Research
```python
# Combine research papers + lecture videos
papers = get_pdf_text("ml_paper.pdf")
lecture = get_youtube_transcript("stanford_lecture_url")
combined = papers + " " + lecture

# Build knowledge base
chunks = get_chunks(combined, 300, 75)
vectors, model = vector_embedding(chunks)

# Ask questions
answer = search_best_chunks("What is gradient descent?", model, vectors, chunks)
```

### Use Case 2: Company Documentation
```python
# Aggregate all company knowledge
handbook = get_pdf_text("employee_handbook.pdf")
training = get_youtube_transcript("onboarding_video")
policies = reading_data("policies.txt")

# Create searchable knowledge base
all_docs = handbook + " " + training + " " + policies
# ... process through RAG ...
```

### Use Case 3: Learning Assistant
```python
# Build personal study guide
textbook = get_pdf_text("chapter5.pdf")
tutorial = get_youtube_transcript("khan_academy_url")
notes = reading_data("my_notes.txt")

# RAG-powered study assistant
knowledge_base = textbook + " " + tutorial + " " + notes
# ... answer study questions ...
```

---

## ğŸ” Error Handling Summary

All three modules implement consistent error handling:

| Error Type | Behavior |
|------------|----------|
| File not found | Returns error message string |
| Invalid format | Returns error message string |
| Network issues | Returns error message string |
| Empty content | Returns empty string or message |
| No crash | âœ… Always returns a string |

**Check for errors**:
```python
result = get_pdf_text("file.pdf")
if result.startswith("âŒ"):
    print("Error occurred:", result)
else:
    print("Success!")
```

---

## ğŸ“ Best Practices

### 1. Chunk Size Selection
- **Small files** (< 5 pages): chunk_size=100-150
- **Medium files** (5-20 pages): chunk_size=200-300
- **Large files** (> 20 pages): chunk_size=300-500

### 2. Overlap Strategy
- **High precision needed**: overlap=50-100
- **General use**: overlap=20-50
- **Fast processing**: overlap=10-20

### 3. Multi-Source Integration
```python
# Weight different sources if needed
pdf_text = get_pdf_text("primary.pdf")
youtube_text = get_youtube_transcript(url)

# Primary source repeated for higher weight
combined = pdf_text + " " + pdf_text + " " + youtube_text
```

### 4. Pre-processing
```python
# Clean extracted text before chunking
text = get_pdf_text("document.pdf")
text = text.replace("\n\n", " ")  # Remove extra newlines
text = ' '.join(text.split())      # Normalize whitespace
```

---

## ğŸ¯ Quick Reference Commands

```bash
# Create sample PDF for testing
python create_sample_pdf.py

# Quick PDF test
python quick_test_pdf.py

# Test error handling
python test_pdf_errors.py

# Full RAG demo with PDF
python pdf_rag_example.py

# Full RAG demo with YouTube
python youtube_rag_example.py

# Run main RAG application
python main.py
```

---

## ğŸ“š Documentation Files

- **RAG_SYSTEM_DOCUMENTATION.md** - Complete system overview
- **YOUTUBE_INGESTION_DOCS.md** - YouTube module details
- **PDF_INGESTION_DOCS.md** - PDF module details
- **README.md** - Original project documentation
- **This file** - Multi-source ingestion guide

---

## ğŸš€ Next Steps

With all three ingestion modules complete, you can now:

1. âœ… Ingest data from **any source** (text, video, PDF)
2. âœ… Build **multi-modal knowledge bases**
3. âœ… Create **domain-specific RAG systems**
4. âœ… Scale to **production workloads**

### Future Enhancements
- [ ] Web scraping module (BeautifulSoup)
- [ ] Audio transcription (Whisper API)
- [ ] Database integration (SQL/NoSQL)
- [ ] Cloud storage support (S3, GCS)
- [ ] Real-time data streams
- [ ] Document OCR for scanned PDFs

---

**Status**: ğŸ‰ All Core Ingestion Modules Complete!  
**Last Updated**: January 7, 2026  
**Ready for**: Production Use
